# TSE (Temporal-Self-Erasing) ä½¿ç”¨æŒ‡å—

## æ–¹æ³•ç®€ä»‹

TSE (Temporal-Self-Erasing) æ˜¯AAAI 2025çš„ä¸€ç§æ–°å‹SNNç›‘ç£æ–¹æ³•,é€šè¿‡åŠ¨æ€æ“¦é™¤ä¹‹å‰æ—¶é—´æ­¥çš„é«˜æ¿€æ´»åŒºåŸŸ,è¿«ä½¿ç½‘ç»œåœ¨ä¸åŒæ—¶é—´æ­¥æ¢ç´¢æ–°çš„åˆ¤åˆ«æ€§åŒºåŸŸ,ä»è€Œè§£å†³SNNä¸­åå‘ä¼ æ’­æ¢¯åº¦åœ¨æ—¶é—´æ­¥ä¸Šç›¸åŒå¯¼è‡´ç‰¹å¾è¡¨ç¤ºç›¸ä¼¼çš„é—®é¢˜ã€‚

### æ ¸å¿ƒæ€æƒ³

**é—®é¢˜**: SNNåœ¨åå‘ä¼ æ’­æ—¶,æ‰€æœ‰æ—¶é—´æ­¥æ¥æ”¶ç›¸åŒçš„æ¢¯åº¦,å¯¼è‡´å­¦åˆ°çš„ç‰¹å¾è¡¨ç¤ºé«˜åº¦ç›¸ä¼¼ã€‚

**è§£å†³æ–¹æ¡ˆ**: 
1. ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ (t=0): ä½¿ç”¨åŸå§‹ç‰¹å¾æ­£å¸¸è®­ç»ƒ
2. åç»­æ—¶é—´æ­¥ (t>0): 
   - è®¡ç®—å‰é¢æ—¶é—´æ­¥çš„å¹³å‡é¢„æµ‹å›¾
   - æ‰¾å‡ºé«˜ç½®ä¿¡åº¦çš„åŒºåŸŸ(é«˜äºå›ºå®šé˜ˆå€¼Ï„_fæˆ–åŠ¨æ€é˜ˆå€¼Ï„_d)
   - æ“¦é™¤(æŠ‘åˆ¶)è¿™äº›åŒºåŸŸ
   - å¼ºåˆ¶ç½‘ç»œå…³æ³¨æ–°çš„åŒºåŸŸ

### ç®—æ³•æµç¨‹

å¯¹äºæ¯ä¸ªæ—¶é—´æ­¥t:

1. **ç”Ÿæˆåˆ†ç±»é¢„æµ‹å›¾** (Eq.7):
   ```
   P_t(c, i, j) = FC(F_t(i,j))  # å¯¹æ¯ä¸ªç©ºé—´ä½ç½®(i,j)è¿›è¡Œåˆ†ç±»
   ```

2. **è®¡ç®—å¹³å‡é¢„æµ‹** (t>0æ—¶):
   ```
   PÌ„_{t-1} = Softmax(mean(P_0, P_1, ..., P_{t-1}))
   ```

3. **æå–çœŸå®ç±»åˆ«çš„æ¦‚ç‡å›¾**:
   ```
   P_{t-1}_y(i,j) = PÌ„_{t-1}(y, i, j)  # yæ˜¯çœŸå®æ ‡ç­¾
   ```

4. **è®¡ç®—åŠ¨æ€é˜ˆå€¼** (Eq.9):
   ```
   Ï„_d = mean(P_{t-1}_y) + Îº Ã— std(P_{t-1}_y)
   ```

5. **æ„å»ºæ“¦é™¤æ©ç ** (Eq.10):
   ```
   M_t(i,j) = {
       0,  if P_{t-1}_y(i,j) >= max(Ï„_f, Ï„_d)  # æ“¦é™¤é«˜ç½®ä¿¡åŒºåŸŸ
       1,  otherwise                            # ä¿ç•™å…¶ä»–åŒºåŸŸ
   }
   ```

6. **ç‰¹å¾è°ƒåˆ¶** (Eq.11):
   ```
   FÌƒ_t = F_t âŠ™ M_t  # å…ƒç´ çº§ä¹˜æ³•
   ```

7. **è®¡ç®—æŸå¤±** (Eq.12):
   ```
   L = L_CE(p_1, y) + Î£_{t=2}^T L_CE(pÌƒ_t, y)
   ```
   å…¶ä¸­: pÌƒ_t = FC(GAP(FÌƒ_t))

## ä»£ç å®ç°

### 1. å·²å®ç°çš„åŠŸèƒ½

#### functions.py
æ–°å¢ `TSE_loss()` å‡½æ•°:
```python
def TSE_loss(feature_maps, fc_layer, labels, criterion, tau_f=0.5, kappa=1.0):
    """
    å‚æ•°:
        feature_maps: [B, T, C, H, W] - GAPä¹‹å‰çš„ç‰¹å¾å›¾
        fc_layer: åˆ†ç±»å±‚(nn.Linear)
        labels: [B] - çœŸå®æ ‡ç­¾
        criterion: æŸå¤±å‡½æ•°(CrossEntropyLoss)
        tau_f: å›ºå®šé˜ˆå€¼(é»˜è®¤0.5)
        kappa: åŠ¨æ€é˜ˆå€¼çš„æ ‡å‡†å·®å€æ•°(é»˜è®¤1.0)
    
    è¿”å›:
        total_loss: æ‰€æœ‰æ—¶é—´æ­¥çš„æ€»æŸå¤±
    """
```

#### models/resnet_models.py
ä¿®æ”¹ `forward()` æ–¹æ³•æ”¯æŒè¿”å›GAPä¹‹å‰çš„ç‰¹å¾:
```python
def forward(self, x, return_features=False):
    output, features_before_gap = self._forward_impl(x)
    if return_features:
        return output, features_before_gap
    else:
        return output
```

#### main_training_distribute_improved.py
1. æ·»åŠ TSEç›¸å…³å‚æ•°:
```python
--tse / --no-tse  # å¯ç”¨/ç¦ç”¨TSE (é»˜è®¤: False)
--tau-f           # å›ºå®šé˜ˆå€¼ (é»˜è®¤: 0.5)
--kappa           # åŠ¨æ€é˜ˆå€¼çš„Îºå‚æ•° (é»˜è®¤: 1.0)
```

2. ä¿®æ”¹train()å‡½æ•°æ”¯æŒTSEè®­ç»ƒ

### 2. ä½¿ç”¨æ–¹æ³•

#### åŸºæœ¬ç”¨æ³•

ä½¿ç”¨TSEè®­ç»ƒResNet19:
```bash
python main_training_distribute_improved.py \
    --data-path /path/to/cifar10 \
    --dataset CIFAR10 \
    --arch resnet19 \
    --T 4 \
    --batch-size 128 \
    --epochs 320 \
    --lr 0.1 \
    --tse \
    --tau-f 0.5 \
    --kappa 1.0
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--tse` | flag | False | å¯ç”¨TSEè®­ç»ƒ |
| `--no-tse` | flag | - | ç¦ç”¨TSEè®­ç»ƒ(æ˜¾å¼) |
| `--tau-f` | float | 0.5 | å›ºå®šé˜ˆå€¼Ï„_f,æ§åˆ¶æ“¦é™¤çš„æœ€ä½ç½®ä¿¡åº¦ |
| `--kappa` | float | 1.0 | åŠ¨æ€é˜ˆå€¼çš„æ ‡å‡†å·®å€æ•°Îº |

#### ä¸å…¶ä»–æ–¹æ³•ç»„åˆ

**ä¸è¦åŒæ—¶ä½¿ç”¨TETå’ŒTSE!** å®ƒä»¬æ˜¯äº’æ–¥çš„è®­ç»ƒæ–¹æ³•:

âœ… **æ­£ç¡®**:
```bash
# åªç”¨TSE
python main_training_distribute_improved.py --tse --tau-f 0.5 ...

# åªç”¨TET
python main_training_distribute_improved.py --tet --means 1.0 --lamb 0.05 ...

# éƒ½ä¸ç”¨(æ ‡å‡†è®­ç»ƒ)
python main_training_distribute_improved.py --no-tet --no-tse ...
```

âŒ **é”™è¯¯**:
```bash
# ä¸è¦åŒæ—¶å¯ç”¨TETå’ŒTSE!
python main_training_distribute_improved.py --tse --tet ...  # é”™è¯¯!
```

### 3. è¶…å‚æ•°è°ƒä¼˜å»ºè®®

#### Ï„_f (å›ºå®šé˜ˆå€¼)
- **æ¨èå€¼**: 0.5 (è®ºæ–‡é»˜è®¤)
- **èŒƒå›´**: 0.3 ~ 0.7
- **ä½œç”¨**: æ§åˆ¶æ“¦é™¤çš„"ç¡¬æ€§"ä¸‹é™
  - è¾ƒå°å€¼(0.3): æ“¦é™¤æ›´å¤šåŒºåŸŸ,æ¢ç´¢æ€§æ›´å¼º,å¯èƒ½æŸå¤±æœ‰ç”¨ä¿¡æ¯
  - è¾ƒå¤§å€¼(0.7): åªæ“¦é™¤æé«˜ç½®ä¿¡åŒºåŸŸ,æ›´ä¿å®ˆ

#### Îº (æ ‡å‡†å·®å€æ•°)
- **æ¨èå€¼**: 1.0 (è®ºæ–‡é»˜è®¤)
- **èŒƒå›´**: 0.5 ~ 2.0
- **ä½œç”¨**: æ§åˆ¶åŠ¨æ€é˜ˆå€¼çš„è‡ªé€‚åº”æ€§
  - è¾ƒå°å€¼(0.5): åŠ¨æ€é˜ˆå€¼æ›´ä½,æ“¦é™¤æ›´å¤š
  - è¾ƒå¤§å€¼(2.0): åŠ¨æ€é˜ˆå€¼æ›´é«˜,æ›´è°¨æ…æ“¦é™¤

#### è°ƒä¼˜ç­–ç•¥

1. **å…ˆç”¨é»˜è®¤å€¼** (Ï„_f=0.5, Îº=1.0) è®­ç»ƒbaseline
2. **æ•°æ®é›†ç›¸å…³è°ƒæ•´**:
   - **å¤æ‚æ•°æ®é›†**(ImageNet): å‡å°Ï„_fåˆ°0.4,å¢åŠ æ¢ç´¢
   - **ç®€å•æ•°æ®é›†**(CIFAR-10): å¯ä¿æŒé»˜è®¤æˆ–ç•¥å¾®å¢åŠ Ï„_fåˆ°0.6
3. **è§‚å¯Ÿè®­ç»ƒæ›²çº¿**:
   - **è¿‡æ‹Ÿåˆ**: å‡å°Ï„_fæˆ–Îº,å¢åŠ æ“¦é™¤
   - **æ¬ æ‹Ÿåˆ**: å¢åŠ Ï„_fæˆ–Îº,å‡å°‘æ“¦é™¤

### 4. å®Œæ•´è®­ç»ƒç¤ºä¾‹

#### CIFAR-10 (DVS)
```bash
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    main_training_distribute_improved.py \
    --data-path /data/dvscifar10 \
    --dataset DVS-CIFAR10 \
    --arch resnet19 \
    --T 10 \
    --batch-size 20 \
    --epochs 320 \
    --lr 0.1 \
    --tse \
    --tau-f 0.5 \
    --kappa 1.0 \
    --workers 4
```

#### CIFAR-100
```bash
python -m torch.distributed.launch \
    --nproc_per_node=7 \
    main_training_distribute_improved.py \
    --data-path /data/cifar100 \
    --dataset CIFAR-100 \
    --arch resnet19 \
    --T 4 \
    --batch-size 128 \
    --epochs 320 \
    --lr 0.1 \
    --tse \
    --tau-f 0.45 \
    --kappa 1.0 \
    --workers 8
```

### 5. æ¨¡å‹å…¼å®¹æ€§

#### å½“å‰æ”¯æŒ
- âœ… **ResNet19**: å®Œå…¨æ”¯æŒ,å·²ä¿®æ”¹è¿”å›features_before_gap
- âœ… **ResNet18/34/50**: ç†è®ºä¸Šæ”¯æŒ(ç»§æ‰¿è‡ªç›¸åŒåŸºç±»)

#### éœ€è¦é€‚é…
- âš ï¸ **VGG_SNN**: éœ€è¦ç±»ä¼¼ä¿®æ”¹,è¿”å›GAPä¹‹å‰çš„ç‰¹å¾
  
å¦‚éœ€VGGæ”¯æŒ,éœ€ä¿®æ”¹ `models/VGG_models.py`:
```python
def forward(self, x, return_features=False):
    # ... å·ç§¯å±‚ ...
    features_before_gap = x  # ä¿å­˜GAPå‰çš„ç‰¹å¾
    x = self.avgpool(x)
    x = torch.flatten(x, 2)
    x = self.classifier(x)
    
    if return_features:
        return x, features_before_gap
    else:
        return x
```

### 6. é¢„æœŸæ€§èƒ½

æ ¹æ®AAAI 2025è®ºæ–‡:

| æ•°æ®é›† | åŸºçº¿(æ ‡å‡†è®­ç»ƒ) | TSE | æå‡ |
|--------|----------------|-----|------|
| CIFAR-10 | 93.x% | 94.x% | ~1% |
| CIFAR-100 | 70.x% | 72.x% | ~2% |
| DVS-CIFAR10 | 76.x% | 78.x% | ~2% |

*æ³¨: å…·ä½“æ•°å€¼å–å†³äºç½‘ç»œæ¶æ„å’Œè®­ç»ƒè¶…å‚æ•°*

### 7. è°ƒè¯•å’ŒéªŒè¯

#### æ£€æŸ¥TSEæ˜¯å¦ç”Ÿæ•ˆ

åœ¨train()å‡½æ•°ä¸­,TSEå¯ç”¨æ—¶ä¼š:
1. è°ƒç”¨ `model(images, return_features=True)`
2. è·å– `features_before_gap` å¼ é‡
3. è°ƒç”¨ `TSE_loss()` è€Œéæ ‡å‡†lossæˆ–TET_loss

å¯ä»¥æ·»åŠ æ‰“å°éªŒè¯:
```python
if args.TSE:
    print(f"TSE enabled: tau_f={args.tau_f}, kappa={args.kappa}")
    output, features = model(images, return_features=True)
    print(f"Features shape: {features.shape}")  # åº”è¯¥æ˜¯ [B,T,C,H,W]
```

#### å¸¸è§é—®é¢˜

1. **AttributeError: 'ResNet' object has no attribute 'fc2'**
   - åŸå› : ä½¿ç”¨çš„æ¨¡å‹ä¸æ˜¯ResNet19æˆ–æ²¡æœ‰fc2å±‚
   - è§£å†³: æ£€æŸ¥ `--arch` å‚æ•°,ç¡®ä¿æ˜¯resnet19

2. **RuntimeError: Expected 5D tensor, got 4D**
   - åŸå› : features_before_gapç»´åº¦ä¸å¯¹
   - è§£å†³: ç¡®ä¿æ¨¡å‹æ­£ç¡®è¿”å› [B,T,C,H,W] æ ¼å¼çš„ç‰¹å¾

3. **è®­ç»ƒé€Ÿåº¦å˜æ…¢**
   - åŸå› : TSEéœ€è¦é¢å¤–è®¡ç®—é¢„æµ‹å›¾å’Œæ©ç 
   - é¢„æœŸ: æ¯”æ ‡å‡†è®­ç»ƒæ…¢10-20%
   - ä¼˜åŒ–: å¢åŠ  `--workers` æˆ–å‡å°batch size

### 8. è®ºæ–‡å¼•ç”¨

å¦‚æœä½¿ç”¨TSEæ–¹æ³•,è¯·å¼•ç”¨:

```bibtex
@inproceedings{tse2025,
  title={Temporal-Self-Erasing Supervision for Spiking Neural Networks},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2025}
}
```

## å®ç°ç»†èŠ‚

### TSE_losså‡½æ•°å·¥ä½œæµç¨‹

```python
# ä¼ªä»£ç 
for t in range(T):
    # æ­¥éª¤1: ç”Ÿæˆç©ºé—´åˆ†ç±»é¢„æµ‹å›¾
    P_t = classify_each_location(features[t])  # [B,num_classes,H,W]
    
    if t == 0:
        # ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥: ç›´æ¥è®¡ç®—æŸå¤±
        loss_t = CE_loss(GAP(P_t), labels)
    else:
        # æ­¥éª¤2: å¹³å‡ä¹‹å‰çš„é¢„æµ‹
        P_avg = mean(P_0, ..., P_{t-1})
        P_avg = Softmax(P_avg)
        
        # æ­¥éª¤3: æå–çœŸå®ç±»åˆ«çš„æ¦‚ç‡å›¾
        P_y = P_avg[labels]  # [B,H,W]
        
        # æ­¥éª¤4: è®¡ç®—åŠ¨æ€é˜ˆå€¼
        tau_d = mean(P_y) + kappa * std(P_y)
        
        # æ­¥éª¤5: æ„å»ºæ©ç 
        threshold = max(tau_f, tau_d)
        mask = (P_y < threshold).float()  # 0æ“¦é™¤,1ä¿ç•™
        
        # æ­¥éª¤6: è°ƒåˆ¶ç‰¹å¾
        F_erased = features[t] * mask
        
        # æ­¥éª¤7: è®¡ç®—æŸå¤±
        P_erased = classify(GAP(F_erased))
        loss_t = CE_loss(P_erased, labels)
    
    total_loss += loss_t

return total_loss
```

### ä¸TETçš„åŒºåˆ«

| æ–¹é¢ | TET | TSE |
|------|-----|-----|
| **ç›‘ç£æ–¹å¼** | æ‰€æœ‰æ—¶é—´æ­¥ä½¿ç”¨ç›¸åŒæ ‡ç­¾ | æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹ç›‘ç£ |
| **ç‰¹å¾è°ƒåˆ¶** | æ—  | åŠ¨æ€æ“¦é™¤é«˜ç½®ä¿¡åŒºåŸŸ |
| **æŸå¤±å‡½æ•°** | L_CE + Î»Â·L_MSE | Î£ L_CE(pÌƒ_t, y) |
| **æ—¶é—´ä¾èµ–** | æ— æ—¶é—´æ­¥é—´äº¤äº’ | åç»­æ­¥ä¾èµ–å‰é¢æ­¥çš„é¢„æµ‹ |
| **æ­£åˆ™åŒ–** | MSEæ­£åˆ™åŒ–è†œç”µä½ | ç©ºé—´æ©ç æ­£åˆ™åŒ–ç‰¹å¾ |

## æ€»ç»“

TSEæ˜¯ä¸€ç§åˆ›æ–°çš„SNNè®­ç»ƒæ–¹æ³•,é€šè¿‡ç©ºé—´-æ—¶é—´è”åˆç›‘ç£,è§£å†³äº†æ¢¯åº¦ç›¸åŒå¯¼è‡´çš„ç‰¹å¾ç›¸ä¼¼é—®é¢˜ã€‚é›†æˆåˆ°æœ¬ä»£ç åº“å,å¯ä»¥æ–¹ä¾¿åœ°ä¸ç°æœ‰TETæ–¹æ³•åˆ‡æ¢ä½¿ç”¨,ä¸ºSNNè®­ç»ƒæä¾›äº†æ–°çš„é€‰æ‹©ã€‚

**å»ºè®®çš„å®éªŒé¡ºåº**:
1. å…ˆç”¨é»˜è®¤å‚æ•° (Ï„_f=0.5, Îº=1.0) åœ¨å°æ•°æ®é›†(CIFAR-10)ä¸Šæµ‹è¯•
2. ä¸baseline(æ ‡å‡†è®­ç»ƒ)å’ŒTETå¯¹æ¯”æ€§èƒ½
3. åœ¨ç›®æ ‡æ•°æ®é›†ä¸Šè°ƒä¼˜è¶…å‚æ•°
4. è®°å½•è®­ç»ƒæ›²çº¿å’Œæœ€ç»ˆç²¾åº¦

ç¥è®­ç»ƒé¡ºåˆ©! ğŸš€
