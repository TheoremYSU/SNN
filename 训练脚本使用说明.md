# 训练脚本使用说明

## 快速开始

### 1. 修改数据路径

编辑 `train.sh` 文件,修改数据路径:
```bash
DATA_PATH="/home/liuwei/lzx/DVS-CIFAR10"  # 改为你的实际路径
```

### 2. 运行训练

```bash
# 给予执行权限
chmod +x train.sh

# 开始训练
bash train.sh
```

### 3. 查看训练进度

训练会在 `./runs/` 目录下创建实验文件夹,目录结构:
```
runs/
└── vgg_snn_T4_lr0.1_lamb0.0001_20231114_191208/
    ├── checkpoints/
    │   ├── checkpoint_epoch_10.pth.tar
    │   ├── checkpoint_epoch_20.pth.tar
    │   ├── model_best.pth.tar
    │   └── checkpoint_latest.pth.tar
    ├── logs/
    │   └── events.out.tfevents...
    └── config.json
```

使用TensorBoard查看训练曲线:
```bash
tensorboard --logdir=./runs
```
然后在浏览器打开 http://localhost:6006

## 脚本说明

### train.sh - 完整训练脚本

主要参数配置:

```bash
# 数据路径
DATA_PATH="/path/to/DVS-CIFAR10"

# 输出目录(自动创建)
OUTPUT_DIR="./runs"

# 模型参数
MODEL="vgg_snn"      # 或 "resnet19"
T=4                  # 时间步
LAMBDA=1e-4          # MSE损失权重

# 训练参数
EPOCHS=320
BATCH_SIZE=16
LR=0.1
NPROCS=4             # GPU数量

# Checkpoint设置
SAVE_FREQ=10         # 每10个epoch保存一次
RESUME=""            # 留空从头训练,或指定checkpoint路径恢复训练
```

### train_test.sh - 快速测试脚本

使用小参数快速测试代码是否正常运行:
- 只训练2个epoch
- 使用2个GPU
- 小batch size (8)
- 输出到 `./test_runs/` 目录

```bash
bash train_test.sh
```

## 恢复训练

如果训练中断,可以恢复:

1. 找到checkpoint路径:
```bash
CHECKPOINT="./runs/vgg_snn_T4_lr0.1_lamb0.0001_20231114_191208/checkpoints/checkpoint_latest.pth.tar"
```

2. 修改 `train.sh` 中的 `RESUME` 参数:
```bash
RESUME="./runs/vgg_snn_T4_lr0.1_lamb0.0001_20231114_191208/checkpoints/checkpoint_latest.pth.tar"
```

3. 重新运行:
```bash
bash train.sh
```

## 常见问题

### 1. 权限错误: Permission denied

**错误信息:**
```
PermissionError: [Errno 13] Permission denied: '/11_14_logs'
```

**原因:** 
- `OUTPUT_DIR` 路径写成了绝对路径如 `/11_14_logs`,没有写权限
- 使用了相对路径但解析错误

**解决方案:**
- 使用相对路径: `OUTPUT_DIR="./runs"`
- 或使用有权限的绝对路径: `OUTPUT_DIR="/home/你的用户名/experiments/runs"`

### 2. 找不到数据路径

**错误信息:**
```
FileNotFoundError: [Errno 2] No such file or directory: '/path/to/DVS-CIFAR10'
```

**解决方案:**
修改 `DATA_PATH` 为实际的数据路径:
```bash
DATA_PATH="/home/liuwei/lzx/DVS-CIFAR10"
```

### 3. GPU数量不匹配

**错误信息:**
```
RuntimeError: CUDA out of memory
```

**解决方案:**
根据可用GPU数量调整 `NPROCS`:
```bash
# 查看可用GPU
nvidia-smi

# 假设有4个GPU
NPROCS=4
```

## 命令行直接运行

也可以不使用脚本,直接运行Python命令:

```bash
python -u main_training_distribute_improved.py \
    --data-path /home/liuwei/lzx/DVS-CIFAR10 \
    --output-dir ./runs \
    --model vgg_snn \
    --T 4 \
    --lamb 1e-4 \
    --epochs 320 \
    --batch-size 16 \
    --lr 0.1 \
    --workers 4 \
    --nprocs 4 \
    --save-freq 10
```

## 所有可用参数

查看完整参数列表:
```bash
python main_training_distribute_improved.py --help
```

主要参数:
- `--data-path`: 数据集路径 (必需)
- `--output-dir`: 输出目录,默认 `./runs`
- `--exp-name`: 实验名称,留空自动生成
- `--model`: 模型名称 (`vgg_snn` / `resnet19`)
- `--T`: 时间步数
- `--lamb`: MSE损失权重
- `--epochs`: 训练epoch数
- `--batch-size`: Batch size
- `--lr`: 学习率
- `--nprocs`: GPU数量
- `--save-freq`: Checkpoint保存频率 (每N个epoch)
- `--resume`: 恢复训练的checkpoint路径
- `--no-tensorboard`: 禁用TensorBoard

## 目录自动创建

改进版代码会自动创建所需目录:
1. 检查 `output-dir` 是否存在,不存在则创建
2. 在 `output-dir` 下创建实验文件夹 (根据 `exp-name`)
3. 创建 `checkpoints/` 和 `logs/` 子目录
4. 保存 `config.json` 记录所有超参数

**关键改进:**
- 自动将相对路径转换为绝对路径
- 自动展开 `~` 到用户主目录
- 只在主进程(rank 0)创建目录,避免多进程竞争
- 提供清晰的错误信息
